{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb1a753",
   "metadata": {},
   "source": [
    "# Laboratorio 8 \n",
    "    - Francis Aguilar - 22243\n",
    "    - César López - 22535\n",
    "    - Gerardo Pineda -22880\n",
    "    - Angela García -22869 \n",
    "    - Joaquin Campos - 22155\n",
    "\n",
    "\n",
    "enlace al repositorio: https://github.com/angelargd8/lab8-deep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b32f9",
   "metadata": {},
   "source": [
    "# Task 1 - Práctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3888b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058fe45",
   "metadata": {},
   "source": [
    "## 1. Preparacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8850809c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjcam\\AppData\\Local\\Temp\\ipykernel_31100\\3001687787.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby([\"store\",\"item\"], group_keys=False).apply(_clip)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>477.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>531.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>2866.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>2574.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       store  item       date   sales\n",
       "0          1     1 2013-01-01   331.0\n",
       "1          1     1 2013-02-01   322.0\n",
       "2          1     1 2013-03-01   477.0\n",
       "3          1     1 2013-04-01   522.0\n",
       "4          1     1 2013-05-01   531.0\n",
       "...      ...   ...        ...     ...\n",
       "29995     10    50 2017-08-01  2866.0\n",
       "29996     10    50 2017-09-01  2586.0\n",
       "29997     10    50 2017-10-01  2507.0\n",
       "29998     10    50 2017-11-01  2574.0\n",
       "29999     10    50 2017-12-01  1987.0\n",
       "\n",
       "[30000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values([\"store\", \"item\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "df[\"sales\"] = pd.to_numeric(df[\"sales\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "def _clip(g):\n",
    "    lo, hi = g[\"sales\"].quantile([0.01, 0.99]).values\n",
    "    g[\"sales\"] = g[\"sales\"].clip(lo, hi)\n",
    "    return g\n",
    "df = df.groupby([\"store\",\"item\"], group_keys=False).apply(_clip)\n",
    "\n",
    "\n",
    "if df[\"date\"].dt.to_period(\"M\").nunique() < df[\"date\"].nunique():\n",
    "    df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "    df = (df.groupby([\"store\",\"item\",\"ym\"], as_index=False)[\"sales\"].sum()\n",
    "            .rename(columns={\"ym\":\"date\"}))\n",
    "\n",
    "all_months = pd.DataFrame({\"date\": pd.date_range(df[\"date\"].min(), df[\"date\"].max(), freq=\"MS\")})\n",
    "pairs = df[[\"store\",\"item\"]].drop_duplicates()\n",
    "panel = pairs.merge(all_months, how=\"cross\")\n",
    "df = (panel.merge(df, on=[\"store\",\"item\",\"date\"], how=\"left\")\n",
    "           .sort_values([\"store\",\"item\",\"date\"])\n",
    "           .reset_index(drop=True))\n",
    "df[\"sales\"] = df[\"sales\"].fillna(0.0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717ea191",
   "metadata": {},
   "source": [
    "## 2.Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f4566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIST = 18   # meses de historia por ventana\n",
    "HORIZON = 3 # meses a predecir\n",
    "months = df[\"date\"].sort_values().drop_duplicates().to_numpy()\n",
    "test_months = months[-HORIZON:]             # últimos 3 meses -> test\n",
    "val_months  = months[-(HORIZON*2): -HORIZON]      # 3 meses previos -> val\n",
    "train_months= months[:-(HORIZON*2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a3a73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> X_train (17000, 18, 1) y_train (17000, 3) X_val (1500, 18, 1) y_val (1500, 3) X_test (1500, 18, 1) y_test (1500, 3)\n"
     ]
    }
   ],
   "source": [
    "def make_sequences(group_df, hist=18, horizon=-3, scaler=None):\n",
    "    g = group_df.sort_values(\"date\").copy()\n",
    "    sales = g[\"sales\"].values.reshape(-1,1)\n",
    "    s_sc = scaler.transform(sales)\n",
    "\n",
    "    X, y, dates_end = [], [], []\n",
    "    for end in range(hist, len(s_sc) - horizon + 1):\n",
    "        X.append(s_sc[end-hist:end, :])     \n",
    "        y.append(s_sc[end:end+horizon, 0])\n",
    "        dates_end.append(g[\"date\"].iloc[end+horizon-1])\n",
    "    return np.array(X), np.array(y), np.array(dates_end)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = [], [], [], [], [], []\n",
    "pairs_index_test = []   \n",
    "\n",
    "for (store, item), g in df.groupby([\"store\",\"item\"]):\n",
    "    g = g.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    # necesitamos mínimo hist+horizon meses en train para ajustar el scaler de forma robusta\n",
    "    g_train = g[g[\"date\"].isin(train_months)].copy()\n",
    "    if len(g_train) < HIST + HORIZON:\n",
    "        continue\n",
    "\n",
    "    scaler = RobustScaler(quantile_range=(5,95))\n",
    "    scaler.fit(g_train[[\"sales\"]].values)\n",
    "\n",
    "    X_all, y_all, dates_end = make_sequences(g, HIST, HORIZON, scaler)\n",
    "\n",
    "    for Xi, yi, d_end in zip(X_all, y_all, dates_end):\n",
    "        if d_end in test_months:\n",
    "            X_test.append(Xi); y_test.append(yi); pairs_index_test.append((store,item,d_end))\n",
    "        elif d_end in val_months:\n",
    "            X_val.append(Xi);  y_val.append(yi)\n",
    "        elif d_end in train_months:\n",
    "            X_train.append(Xi); y_train.append(yi)\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_val,   y_val   = np.array(X_val),   np.array(y_val)\n",
    "X_test,  y_test  = np.array(X_test),  np.array(y_test)\n",
    "\n",
    "print(\"Shapes ->\",\n",
    "      \"X_train\", X_train.shape, \"y_train\", y_train.shape,\n",
    "      \"X_val\",   X_val.shape,   \"y_val\",   y_val.shape,\n",
    "      \"X_test\",  X_test.shape,  \"y_test\",  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ba57c",
   "metadata": {},
   "source": [
    "## 3 y 4  Seleccion de modelo y arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c27a700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,251</span> (83.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,251\u001b[0m (83.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,251</span> (83.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,251\u001b[0m (83.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LR = 1e-3\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(HIST, 1)),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(HORIZON)\n",
    "])\n",
    "model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=optimizers.Adam(learning_rate=LR),\n",
    "    metrics=[tf.keras.metrics.MeanAbsoluteError(name=\"mae\")]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfdc965",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento con EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01e8b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 256\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea431f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0730 - mae: 0.2211 - val_loss: 0.0170 - val_mae: 0.0957 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0173 - mae: 0.1040 - val_loss: 0.0110 - val_mae: 0.0794 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0135 - mae: 0.0924 - val_loss: 0.0082 - val_mae: 0.0705 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0855 - val_loss: 0.0075 - val_mae: 0.0682 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0106 - mae: 0.0815 - val_loss: 0.0072 - val_mae: 0.0674 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0100 - mae: 0.0792 - val_loss: 0.0062 - val_mae: 0.0625 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0094 - mae: 0.0765 - val_loss: 0.0064 - val_mae: 0.0635 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0090 - mae: 0.0749 - val_loss: 0.0060 - val_mae: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0086 - mae: 0.0731 - val_loss: 0.0055 - val_mae: 0.0589 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0085 - mae: 0.0726 - val_loss: 0.0054 - val_mae: 0.0586 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0083 - mae: 0.0715 - val_loss: 0.0052 - val_mae: 0.0579 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0081 - mae: 0.0705 - val_loss: 0.0051 - val_mae: 0.0574 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0079 - mae: 0.0701 - val_loss: 0.0050 - val_mae: 0.0568 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0078 - mae: 0.0694 - val_loss: 0.0051 - val_mae: 0.0571 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0074 - mae: 0.0674 - val_loss: 0.0047 - val_mae: 0.0551 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0074 - mae: 0.0674 - val_loss: 0.0047 - val_mae: 0.0550 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0071 - mae: 0.0659 - val_loss: 0.0047 - val_mae: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0070 - mae: 0.0658 - val_loss: 0.0048 - val_mae: 0.0558 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0069 - mae: 0.0655 - val_loss: 0.0046 - val_mae: 0.0541 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0068 - mae: 0.0645 - val_loss: 0.0044 - val_mae: 0.0531 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0067 - mae: 0.0639 - val_loss: 0.0044 - val_mae: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0065 - mae: 0.0630 - val_loss: 0.0044 - val_mae: 0.0527 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0065 - mae: 0.0632 - val_loss: 0.0042 - val_mae: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0063 - mae: 0.0622 - val_loss: 0.0044 - val_mae: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0062 - mae: 0.0615 - val_loss: 0.0039 - val_mae: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0061 - mae: 0.0610 - val_loss: 0.0043 - val_mae: 0.0527 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0060 - mae: 0.0606 - val_loss: 0.0037 - val_mae: 0.0479 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0061 - mae: 0.0610 - val_loss: 0.0044 - val_mae: 0.0528 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0058 - mae: 0.0597 - val_loss: 0.0033 - val_mae: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0058 - mae: 0.0593 - val_loss: 0.0033 - val_mae: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0057 - mae: 0.0590 - val_loss: 0.0031 - val_mae: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0055 - mae: 0.0579 - val_loss: 0.0031 - val_mae: 0.0438 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0055 - mae: 0.0580 - val_loss: 0.0029 - val_mae: 0.0423 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0056 - mae: 0.0580 - val_loss: 0.0029 - val_mae: 0.0425 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0054 - mae: 0.0574 - val_loss: 0.0029 - val_mae: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0053 - mae: 0.0569 - val_loss: 0.0029 - val_mae: 0.0423 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0053 - mae: 0.0570 - val_loss: 0.0030 - val_mae: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0052 - mae: 0.0563 - val_loss: 0.0028 - val_mae: 0.0413 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0052 - mae: 0.0565 - val_loss: 0.0028 - val_mae: 0.0414 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0052 - mae: 0.0564 - val_loss: 0.0028 - val_mae: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0051 - mae: 0.0556 - val_loss: 0.0030 - val_mae: 0.0431 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0051 - mae: 0.0555 - val_loss: 0.0030 - val_mae: 0.0431 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0051 - mae: 0.0557 - val_loss: 0.0028 - val_mae: 0.0414 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0050 - mae: 0.0553 - val_loss: 0.0028 - val_mae: 0.0415 - learning_rate: 5.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0050 - mae: 0.0553 - val_loss: 0.0029 - val_mae: 0.0424 - learning_rate: 5.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0049 - mae: 0.0545 - val_loss: 0.0029 - val_mae: 0.0425 - learning_rate: 5.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0049 - mae: 0.0547 - val_loss: 0.0028 - val_mae: 0.0416 - learning_rate: 5.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0049 - mae: 0.0545 - val_loss: 0.0029 - val_mae: 0.0423 - learning_rate: 5.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0048 - mae: 0.0541 - val_loss: 0.0028 - val_mae: 0.0414 - learning_rate: 2.5000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0048 - mae: 0.0543 - val_loss: 0.0029 - val_mae: 0.0418 - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "es  = callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH,\n",
    "    callbacks=[es, rlr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5175b3e1",
   "metadata": {},
   "source": [
    "## 6. Evaluación del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a7bf075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - mae: 0.0441\n",
      "Loss (MSE): 0.0034\n",
      "MAE: 0.0449\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "Métricas de evaluación:\n",
      "MAE  = 0.0449\n",
      "MSE  = 0.0034\n",
      "RMSE = 0.0581\n",
      "R² = 0.6700\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Evaluación directa con Keras\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Loss (MSE): {test_loss:.4f}\")\n",
    "print(f\"MAE: {test_mae:.4f}\")\n",
    "\n",
    "# Predicciones sobre el conjunto de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Cálculo de métricas adicionales\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nMétricas de evaluación:\")\n",
    "print(f\"MAE  = {mae:.4f}\")\n",
    "print(f\"MSE  = {mse:.4f}\")\n",
    "print(f\"RMSE = {rmse:.4f}\")\n",
    "print(f\"R² = {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff56fc",
   "metadata": {},
   "source": [
    "Los resultados del modelo indican un desempeño bastante bueno en términos de error absoluto y cuadrático: la **MAE de 0.0536** sugiere que, en promedio, las predicciones se desvían aproximadamente 0.054 unidades de los valores reales, mientras que el **RMSE de 0.0678** confirma que los errores más grandes no son excesivos, mostrando una distribución de errores relativamente uniforme. La **MSE de 0.0046** respalda esta observación al reflejar un error cuadrático pequeño. Sin embargo, el **R² de 0.5155** indica que el modelo explica alrededor del 51% de la variabilidad de los datos, lo que significa que aún existe una parte considerable de la variación que no se captura. En conjunto, el modelo predice con precisión moderada, con errores bajos, pero podría mejorar en la capacidad de capturar toda la dinámica de los datos. También puede ser indice de sobreajuste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235b41d",
   "metadata": {},
   "source": [
    "## 7. Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bfa2911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(units=64, stacked=False, dropout=0.0, dense_units=64, lr=1e-3, output_size=None):\n",
    "    if output_size is None:\n",
    "        output_size = HORIZON\n",
    "\n",
    "    m = models.Sequential()\n",
    "    m.add(layers.Input(shape=(HIST, 1)))\n",
    "\n",
    "    if stacked:\n",
    "        m.add(layers.LSTM(units, return_sequences=True))\n",
    "        if dropout > 0:\n",
    "            m.add(layers.Dropout(dropout))\n",
    "        m.add(layers.LSTM(units))\n",
    "    else:\n",
    "        m.add(layers.LSTM(units))\n",
    "\n",
    "    if dropout > 0:\n",
    "        m.add(layers.Dropout(dropout))\n",
    "\n",
    "    if dense_units and dense_units > 0:\n",
    "        m.add(layers.Dense(dense_units, activation=\"relu\"))\n",
    "\n",
    "    m.add(layers.Dense(output_size, activation=\"linear\"))\n",
    "\n",
    "    opt = optimizers.Adam(learning_rate=lr)\n",
    "    m.compile(optimizer=opt, loss=\"mse\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf63cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probando 144 combinaciones...\n",
      "\n",
      "[1/144] {'units': 32, 'stacked': False, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[2/144] {'units': 32, 'stacked': False, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[3/144] {'units': 32, 'stacked': False, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[4/144] {'units': 32, 'stacked': False, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[5/144] {'units': 32, 'stacked': False, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[6/144] {'units': 32, 'stacked': False, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[7/144] {'units': 32, 'stacked': False, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[8/144] {'units': 32, 'stacked': False, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[9/144] {'units': 32, 'stacked': False, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[10/144] {'units': 32, 'stacked': False, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[11/144] {'units': 32, 'stacked': False, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[12/144] {'units': 32, 'stacked': False, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[13/144] {'units': 32, 'stacked': False, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[14/144] {'units': 32, 'stacked': False, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[15/144] {'units': 32, 'stacked': False, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[16/144] {'units': 32, 'stacked': False, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[17/144] {'units': 32, 'stacked': False, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[18/144] {'units': 32, 'stacked': False, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[19/144] {'units': 32, 'stacked': False, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[20/144] {'units': 32, 'stacked': False, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[21/144] {'units': 32, 'stacked': False, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[22/144] {'units': 32, 'stacked': False, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[23/144] {'units': 32, 'stacked': False, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[24/144] {'units': 32, 'stacked': False, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[25/144] {'units': 32, 'stacked': True, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[26/144] {'units': 32, 'stacked': True, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[27/144] {'units': 32, 'stacked': True, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[28/144] {'units': 32, 'stacked': True, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[29/144] {'units': 32, 'stacked': True, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[30/144] {'units': 32, 'stacked': True, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[31/144] {'units': 32, 'stacked': True, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[32/144] {'units': 32, 'stacked': True, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[33/144] {'units': 32, 'stacked': True, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[34/144] {'units': 32, 'stacked': True, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[35/144] {'units': 32, 'stacked': True, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[36/144] {'units': 32, 'stacked': True, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[37/144] {'units': 32, 'stacked': True, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[38/144] {'units': 32, 'stacked': True, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[39/144] {'units': 32, 'stacked': True, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[40/144] {'units': 32, 'stacked': True, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[41/144] {'units': 32, 'stacked': True, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[42/144] {'units': 32, 'stacked': True, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[43/144] {'units': 32, 'stacked': True, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[44/144] {'units': 32, 'stacked': True, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[45/144] {'units': 32, 'stacked': True, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[46/144] {'units': 32, 'stacked': True, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[47/144] {'units': 32, 'stacked': True, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[48/144] {'units': 32, 'stacked': True, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[49/144] {'units': 64, 'stacked': False, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[50/144] {'units': 64, 'stacked': False, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[51/144] {'units': 64, 'stacked': False, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[52/144] {'units': 64, 'stacked': False, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[53/144] {'units': 64, 'stacked': False, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[54/144] {'units': 64, 'stacked': False, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[55/144] {'units': 64, 'stacked': False, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[56/144] {'units': 64, 'stacked': False, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[57/144] {'units': 64, 'stacked': False, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[58/144] {'units': 64, 'stacked': False, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[59/144] {'units': 64, 'stacked': False, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[60/144] {'units': 64, 'stacked': False, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[61/144] {'units': 64, 'stacked': False, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[62/144] {'units': 64, 'stacked': False, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[63/144] {'units': 64, 'stacked': False, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[64/144] {'units': 64, 'stacked': False, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[65/144] {'units': 64, 'stacked': False, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[66/144] {'units': 64, 'stacked': False, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[67/144] {'units': 64, 'stacked': False, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[68/144] {'units': 64, 'stacked': False, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[69/144] {'units': 64, 'stacked': False, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[70/144] {'units': 64, 'stacked': False, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[71/144] {'units': 64, 'stacked': False, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[72/144] {'units': 64, 'stacked': False, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[73/144] {'units': 64, 'stacked': True, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[74/144] {'units': 64, 'stacked': True, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[75/144] {'units': 64, 'stacked': True, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[76/144] {'units': 64, 'stacked': True, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[77/144] {'units': 64, 'stacked': True, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[78/144] {'units': 64, 'stacked': True, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[79/144] {'units': 64, 'stacked': True, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[80/144] {'units': 64, 'stacked': True, 'dropout': 0.0, 'dense_units': 128, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[81/144] {'units': 64, 'stacked': True, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[82/144] {'units': 64, 'stacked': True, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[83/144] {'units': 64, 'stacked': True, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[84/144] {'units': 64, 'stacked': True, 'dropout': 0.2, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[85/144] {'units': 64, 'stacked': True, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[86/144] {'units': 64, 'stacked': True, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[87/144] {'units': 64, 'stacked': True, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[88/144] {'units': 64, 'stacked': True, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[89/144] {'units': 64, 'stacked': True, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[90/144] {'units': 64, 'stacked': True, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[91/144] {'units': 64, 'stacked': True, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[92/144] {'units': 64, 'stacked': True, 'dropout': 0.4, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[93/144] {'units': 64, 'stacked': True, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[94/144] {'units': 64, 'stacked': True, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[95/144] {'units': 64, 'stacked': True, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[96/144] {'units': 64, 'stacked': True, 'dropout': 0.4, 'dense_units': 128, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[97/144] {'units': 128, 'stacked': False, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.001, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[98/144] {'units': 128, 'stacked': False, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.001, 'batch': 256, 'epochs': 60}\n",
      "\n",
      "[99/144] {'units': 128, 'stacked': False, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "\n",
      "[100/144] {'units': 128, 'stacked': False, 'dropout': 0.0, 'dense_units': 64, 'lr': 0.0005, 'batch': 256, 'epochs': 60}\n"
     ]
    }
   ],
   "source": [
    "import itertools, time\n",
    "\n",
    "param_grid = {\n",
    "    \"units\": [32, 64, 128],\n",
    "    \"stacked\": [False, True],\n",
    "    \"dropout\": [0.0, 0.2, 0.4],\n",
    "    \"dense_units\": [64, 128],\n",
    "    \"lr\": [1e-3, 5e-4],\n",
    "    \"batch\": [128, 256],\n",
    "    \"epochs\": [60],\n",
    "}\n",
    "\n",
    "keys = list(param_grid.keys())\n",
    "combos = list(itertools.product(*[param_grid[k] for k in keys]))\n",
    "\n",
    "results = []\n",
    "print(f\"Probando {len(combos)} combinaciones...\")\n",
    "\n",
    "best = {\"val_loss\": np.inf, \"combo\": None, \"hist\": None}\n",
    "\n",
    "for i, combo in enumerate(combos, 1):\n",
    "    params = dict(zip(keys, combo))\n",
    "    print(f\"\\n[{i}/{len(combos)}] {params}\")\n",
    "\n",
    "    model = build_lstm_model(\n",
    "        units=params[\"units\"],\n",
    "        stacked=params[\"stacked\"],\n",
    "        dropout=params[\"dropout\"],\n",
    "        dense_units=params[\"dense_units\"],\n",
    "        lr=params[\"lr\"],\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    hist = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=params[\"epochs\"],\n",
    "        batch_size=params[\"batch\"],\n",
    "        callbacks=[es, rlr],\n",
    "        verbose=0\n",
    "    )\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    val_loss = float(min(hist.history[\"val_loss\"]))\n",
    "    train_loss = float(min(hist.history[\"loss\"]))\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"time_s\": round(dt, 2)\n",
    "    })\n",
    "\n",
    "    if val_loss < best[\"val_loss\"]:\n",
    "        best = {\"val_loss\": val_loss, \"combo\": params, \"hist\": hist.history}\n",
    "\n",
    "# DataFrame con ranking de combinaciones\n",
    "hp_results = pd.DataFrame(results).sort_values(\"val_loss\", ascending=True).reset_index(drop=True)\n",
    "display(hp_results.head(10)) \n",
    "\n",
    "print(\"\\nMejor combinación encontrada:\")\n",
    "print(best[\"combo\"])\n",
    "print(f\"Mejor val_loss: {best['val_loss']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e170a1",
   "metadata": {},
   "source": [
    "## 8. Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642f182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo final con mejores hiperparámetros:\n",
      " {'units': 32, 'stacked': False, 'dropout': 0.2, 'dense_units': 128, 'lr': 0.0005, 'batch': 128, 'epochs': 60}\n",
      "Epoch 1/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0534\n",
      "Epoch 2/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0130\n",
      "Epoch 3/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0100\n",
      "Epoch 4/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0083\n",
      "Epoch 5/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0071\n",
      "Epoch 6/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0063\n",
      "Epoch 7/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0056\n",
      "Epoch 8/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0050\n",
      "Epoch 9/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0047\n",
      "Epoch 10/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0043\n",
      "Epoch 11/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0041\n",
      "Epoch 12/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0040\n",
      "Epoch 13/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0039\n",
      "Epoch 14/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037\n",
      "Epoch 15/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0037\n",
      "Epoch 16/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0036\n",
      "Epoch 17/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035\n",
      "Epoch 18/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0035\n",
      "Epoch 19/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034\n",
      "Epoch 20/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0034\n",
      "Epoch 21/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033\n",
      "Epoch 22/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033\n",
      "Epoch 23/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0033\n",
      "Epoch 24/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032\n",
      "Epoch 25/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032\n",
      "Epoch 26/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0032\n",
      "Epoch 27/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0032\n",
      "Epoch 28/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0031\n",
      "Epoch 29/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0031\n",
      "Epoch 30/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0031\n",
      "Epoch 31/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0031\n",
      "Epoch 32/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0030\n",
      "Epoch 33/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0030\n",
      "Epoch 34/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0030\n",
      "Epoch 35/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0030\n",
      "Epoch 36/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0030\n",
      "Epoch 37/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0030\n",
      "Epoch 38/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 0.0030\n",
      "Epoch 39/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 0.0029\n",
      "Epoch 40/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0029\n",
      "Epoch 41/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029\n",
      "Epoch 42/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029\n",
      "Epoch 43/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029\n",
      "Epoch 44/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029\n",
      "Epoch 45/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028\n",
      "Epoch 46/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0029\n",
      "Epoch 47/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028\n",
      "Epoch 48/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0028\n",
      "Epoch 49/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028\n",
      "Epoch 50/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0028\n",
      "Epoch 51/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028\n",
      "Epoch 52/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0028\n",
      "Epoch 53/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028\n",
      "Epoch 54/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028\n",
      "Epoch 55/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028\n",
      "Epoch 56/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028\n",
      "Epoch 57/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028\n",
      "Epoch 58/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028\n",
      "Epoch 59/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0028\n",
      "Epoch 60/60\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0027\n",
      "\n",
      "Muestra de pronósticos (multistep):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred_t+1</th>\n",
       "      <th>y_pred_t+2</th>\n",
       "      <th>y_pred_t+3</th>\n",
       "      <th>y_true_t+1</th>\n",
       "      <th>y_true_t+2</th>\n",
       "      <th>y_true_t+3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.472641</td>\n",
       "      <td>0.285963</td>\n",
       "      <td>0.175158</td>\n",
       "      <td>0.496506</td>\n",
       "      <td>0.354297</td>\n",
       "      <td>0.167954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.261710</td>\n",
       "      <td>0.192672</td>\n",
       "      <td>0.222727</td>\n",
       "      <td>0.354297</td>\n",
       "      <td>0.167954</td>\n",
       "      <td>0.187569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.197135</td>\n",
       "      <td>0.266573</td>\n",
       "      <td>-0.101629</td>\n",
       "      <td>0.167954</td>\n",
       "      <td>0.187569</td>\n",
       "      <td>-0.140983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.449907</td>\n",
       "      <td>0.268435</td>\n",
       "      <td>0.172088</td>\n",
       "      <td>0.490977</td>\n",
       "      <td>0.323377</td>\n",
       "      <td>0.143437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.251673</td>\n",
       "      <td>0.178526</td>\n",
       "      <td>0.224042</td>\n",
       "      <td>0.323377</td>\n",
       "      <td>0.143437</td>\n",
       "      <td>0.363477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.202094</td>\n",
       "      <td>0.278771</td>\n",
       "      <td>-0.150915</td>\n",
       "      <td>0.143437</td>\n",
       "      <td>0.363477</td>\n",
       "      <td>-0.137268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.425171</td>\n",
       "      <td>0.251030</td>\n",
       "      <td>0.174483</td>\n",
       "      <td>0.397307</td>\n",
       "      <td>0.298165</td>\n",
       "      <td>0.150192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.264208</td>\n",
       "      <td>0.172248</td>\n",
       "      <td>0.218282</td>\n",
       "      <td>0.298165</td>\n",
       "      <td>0.150192</td>\n",
       "      <td>0.233057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.202146</td>\n",
       "      <td>0.256811</td>\n",
       "      <td>-0.191617</td>\n",
       "      <td>0.150192</td>\n",
       "      <td>0.233057</td>\n",
       "      <td>-0.185706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.430893</td>\n",
       "      <td>0.254424</td>\n",
       "      <td>0.166359</td>\n",
       "      <td>0.413102</td>\n",
       "      <td>0.107553</td>\n",
       "      <td>0.183329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_pred_t+1  y_pred_t+2  y_pred_t+3  y_true_t+1  y_true_t+2  y_true_t+3\n",
       "0    0.472641    0.285963    0.175158    0.496506    0.354297    0.167954\n",
       "1    0.261710    0.192672    0.222727    0.354297    0.167954    0.187569\n",
       "2    0.197135    0.266573   -0.101629    0.167954    0.187569   -0.140983\n",
       "3    0.449907    0.268435    0.172088    0.490977    0.323377    0.143437\n",
       "4    0.251673    0.178526    0.224042    0.323377    0.143437    0.363477\n",
       "5    0.202094    0.278771   -0.150915    0.143437    0.363477   -0.137268\n",
       "6    0.425171    0.251030    0.174483    0.397307    0.298165    0.150192\n",
       "7    0.264208    0.172248    0.218282    0.298165    0.150192    0.233057\n",
       "8    0.202146    0.256811   -0.191617    0.150192    0.233057   -0.185706\n",
       "9    0.430893    0.254424    0.166359    0.413102    0.107553    0.183329"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert 'hp_results' in globals() and len(hp_results) > 0, \"Primero ejecuta la celda de ajuste de hiperparámetros.\"\n",
    "assert 'build_lstm_model' in globals(), \"No se encontró build_lstm_model (defínela en la celda del ajuste).\"\n",
    "\n",
    "best_params = hp_results.iloc[0][[\"units\",\"stacked\",\"dropout\",\"dense_units\",\"lr\",\"batch\",\"epochs\"]].to_dict()\n",
    "print(\"Entrenando modelo final con mejores hiperparámetros:\\n\", best_params)\n",
    "\n",
    "X_tr_full = np.concatenate([X_train, X_val], axis=0)\n",
    "y_tr_full = np.concatenate([y_train, y_val], axis=0)\n",
    "\n",
    "final_model = build_lstm_model(\n",
    "    units=int(best_params[\"units\"]),\n",
    "    stacked=bool(best_params[\"stacked\"]),\n",
    "    dropout=float(best_params[\"dropout\"]),\n",
    "    dense_units=int(best_params[\"dense_units\"]),\n",
    "    lr=float(best_params[\"lr\"]),\n",
    "    output_size=HORIZON\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    X_tr_full, y_tr_full,\n",
    "    epochs=int(best_params[\"epochs\"]),\n",
    "    batch_size=int(best_params[\"batch\"]),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred_test = final_model.predict(X_test, verbose=0)\n",
    "\n",
    "# DataFrame con columnas por mes pronosticado\n",
    "cols_pred = [f\"y_pred_t+{i+1}\" for i in range(HORIZON)]\n",
    "forecast_df = pd.DataFrame(y_pred_test, columns=cols_pred)\n",
    "\n",
    "if 'y_test' in globals() and y_test is not None and getattr(y_test, \"ndim\", 1) == 2 and y_test.shape[1] == HORIZON:\n",
    "    for i in range(HORIZON):\n",
    "        forecast_df[f\"y_true_t+{i+1}\"] = y_test[:, i]\n",
    "\n",
    "print(\"\\nMuestra de pronósticos (multistep):\")\n",
    "display(forecast_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d6bff",
   "metadata": {},
   "source": [
    "# 9. Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f99087e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error\n\u001b[0;32m      7\u001b[0m scalers \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (store, item), g \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m      9\u001b[0m     g_train \u001b[38;5;241m=\u001b[39m g[g[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(train_months)]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(g_train) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m HIST \u001b[38;5;241m+\u001b[39m HORIZON:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "_model = final_model if 'final_model' in globals() else (model if 'model' in globals() else None)\n",
    "assert _model is not None, \"No hay modelo en memoria. Ejecuta las celdas 3–4 o 8.\"\n",
    "\n",
    "if 'forecast_df' not in globals():\n",
    "    assert 'y_pred' in globals(), \"Falta forecast_df e y_pred. Corre la celda 5 o 8 para obtener predicciones.\"\n",
    "    cols_pred = [f\"y_pred_t+{i+1}\" for i in range(HORIZON)]\n",
    "    forecast_df = pd.DataFrame(y_pred, columns=cols_pred)\n",
    "    if 'y_test' in globals() and y_test is not None and getattr(y_test, \"ndim\", 1) == 2 and y_test.shape[1] == HORIZON:\n",
    "        for i in range(HORIZON):\n",
    "            forecast_df[f\"y_true_t+{i+1}\"] = y_test[:, i]\n",
    "\n",
    "for v in [\"df\",\"train_months\",\"X_train\",\"X_test\",\"y_test\",\"pairs_index_test\",\"HIST\",\"HORIZON\",\"test_months\"]:\n",
    "    assert v in globals(), f\"Falta {v}. Ejecuta la celda 2 (genera secuencias).\"\n",
    "\n",
    "scalers = {}\n",
    "for (store, item), g in df.groupby([\"store\",\"item\"]):\n",
    "    g_train = g[g[\"date\"].isin(train_months)].copy()\n",
    "    if len(g_train) >= HIST + HORIZON:\n",
    "        sc = RobustScaler(quantile_range=(5,95))\n",
    "        sc.fit(g_train[[\"sales\"]].values)\n",
    "        scalers[(store, item)] = sc\n",
    "\n",
    "rows = []\n",
    "assert len(pairs_index_test) == len(forecast_df), \"Desalineación entre pairs_index_test y forecast_df.\"\n",
    "\n",
    "for i, (store, item, d_end) in enumerate(pairs_index_test):\n",
    "    sc = scalers.get((store, item))\n",
    "    if sc is None:\n",
    "        continue\n",
    "\n",
    "    horizon_dates = pd.date_range(end=pd.to_datetime(d_end), periods=HORIZON, freq=\"MS\")\n",
    "\n",
    "    y_pred_sc = forecast_df.iloc[i, :HORIZON].to_numpy()\n",
    "    y_true_sc = forecast_df.iloc[i, HORIZON:HORIZON*2].to_numpy() if f\"y_true_t+{HORIZON}\" in forecast_df.columns else None\n",
    "\n",
    "    y_pred = sc.inverse_transform(y_pred_sc.reshape(-1,1)).ravel()\n",
    "    y_true = sc.inverse_transform(y_true_sc.reshape(-1,1)).ravel() if y_true_sc is not None else [np.nan]*HORIZON\n",
    "\n",
    "    for d, yt, yp in zip(horizon_dates, y_true, y_pred):\n",
    "        rows.append((int(store), int(item), pd.to_datetime(d), float(yt), float(yp)))\n",
    "\n",
    "forecast_long = (pd.DataFrame(rows, columns=[\"store\",\"item\",\"date\",\"y_true\",\"y_pred\"])\n",
    "                   .sort_values([\"store\",\"item\",\"date\"])\n",
    "                   .reset_index(drop=True))\n",
    "\n",
    "display(forecast_long.head())\n",
    "\n",
    "def plot_series_monthly(store_id, item_id):\n",
    "    g_hist = (df[(df[\"store\"]==store_id) & (df[\"item\"]==item_id)]\n",
    "                .sort_values(\"date\")[[\"date\",\"sales\"]])\n",
    "    g_pred = (forecast_long[(forecast_long[\"store\"]==store_id) & (forecast_long[\"item\"]==item_id)]\n",
    "                .sort_values(\"date\")[[\"date\",\"y_true\",\"y_pred\"]])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(g_hist[\"date\"], g_hist[\"sales\"], label=\"Real (histórico)\")\n",
    "    if not g_pred.empty:\n",
    "        test_min = g_pred[\"date\"].min(); test_max = g_pred[\"date\"].max()\n",
    "        plt.axvspan(test_min, test_max, alpha=0.08, label=\"Periodo test\")\n",
    "        plt.plot(g_pred[\"date\"], g_pred[\"y_true\"], label=\"Real (test)\")\n",
    "        plt.plot(g_pred[\"date\"], g_pred[\"y_pred\"], label=f\"Pronóstico ({HORIZON}m)\")\n",
    "    plt.title(f\"Store {store_id} · Item {item_id}\")\n",
    "    plt.xlabel(\"Fecha\"); plt.ylabel(\"Ventas\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_series_monthly(1, 1)\n",
    "\n",
    "real_total = forecast_long.groupby(\"date\")[\"y_true\"].sum()\n",
    "pred_total = forecast_long.groupby(\"date\")[\"y_pred\"].sum()\n",
    "\n",
    "plt.figure()\n",
    "real_total.plot(label=\"Real (total test)\")\n",
    "pred_total.reindex(real_total.index).plot(label=\"Pronóstico (total)\")\n",
    "plt.title(\"Ventas totales — Real vs. Pronóstico (periodo test)\")\n",
    "plt.xlabel(\"Fecha\"); plt.ylabel(\"Ventas\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "def rmse(a,b): \n",
    "    return float(np.sqrt(mean_squared_error(a,b)))\n",
    "\n",
    "err = (forecast_long\n",
    "       .groupby([\"store\",\"item\"])\n",
    "       .apply(lambda g: pd.Series({\n",
    "           \"MAE\": mean_absolute_error(g[\"y_true\"], g[\"y_pred\"]),\n",
    "           \"RMSE\": rmse(g[\"y_true\"], g[\"y_pred\"])\n",
    "       }))\n",
    "       .reset_index()\n",
    "       .sort_values(\"RMSE\"))\n",
    "\n",
    "display(err.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd93890",
   "metadata": {},
   "source": [
    "# 10. Interpretabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba47687",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Safety prelude SHAP ---\n",
    "_model = final_model if 'final_model' in globals() else (model if 'model' in globals() else None)\n",
    "assert _model is not None, \"No hay modelo en memoria. Ejecuta 3–4 o 8.\"\n",
    "\n",
    "for v in [\"X_train\",\"X_test\",\"HIST\"]:\n",
    "    assert v in globals(), f\"Falta {v}. Ejecuta la celda 2 (genera las secuencias).\"\n",
    "\n",
    "n_features = 1  # solo 'sales' en tus ventanas (shape: HIST x 1)\n",
    "\n",
    "# Wrapper: aplanado -> predicción -> escalar (media del horizonte)\n",
    "def predict_from_flat(X_flat):\n",
    "    X_seq = X_flat.reshape((-1, HIST, n_features))\n",
    "    yhat = _model.predict(X_seq, verbose=0)   # (n, HORIZON)\n",
    "    return yhat.mean(axis=1)[:, None]         # (n,1)\n",
    "\n",
    "# Submuestreo para velocidad (puedes subir estos números si hay tiempo)\n",
    "rng = np.random.default_rng(7)\n",
    "idx_bg = rng.choice(np.arange(len(X_train)), size=min(200, len(X_train)), replace=False)\n",
    "idx_ex = rng.choice(np.arange(len(X_test)),  size=min(50,  len(X_test)),  replace=False)\n",
    "\n",
    "X_bg_flat = X_train[idx_bg].reshape(len(idx_bg), -1)\n",
    "X_ex_flat = X_test[idx_ex].reshape(len(idx_ex), -1)\n",
    "\n",
    "# KernelExplainer (agnóstico)\n",
    "explainer = shap.KernelExplainer(predict_from_flat, X_bg_flat)\n",
    "shap_values = explainer.shap_values(X_ex_flat, nsamples=200)\n",
    "\n",
    "# Acomodar a (n_muestras, HIST) porque solo 1 feature\n",
    "sv = shap_values[0] if isinstance(shap_values, list) else shap_values\n",
    "sv = sv.reshape(len(X_ex_flat), HIST, n_features)[:, :, 0]   # (n, HIST)\n",
    "\n",
    "# Importancia media absoluta por lag (agregando sobre muestras)\n",
    "lag_importance = np.abs(sv).mean(axis=0)  # (HIST,)\n",
    "lags = np.arange(1, HIST+1)               # 1 = más antiguo … HIST = más reciente (etiqueta)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lags, lag_importance)\n",
    "plt.title(\"Importancia media |SHAP| por lag de 'sales' (ventana mensual)\")\n",
    "plt.xlabel(\"Posición en la ventana (1 = más antiguo … HIST = más reciente)\")\n",
    "plt.ylabel(\"Mean |SHAP|\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# (Opcional) summary plot completo (muchas dimensiones si HIST grande)\n",
    "# nombres_flat = [f\"sales_t-{lag}\" for lag in range(HIST, 0, -1)]\n",
    "# shap.summary_plot(sv.reshape(len(X_ex_flat), -1), X_ex_flat, feature_names=nombres_flat, show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d33a7c0",
   "metadata": {},
   "source": [
    "# Task 2 - Teoría\n",
    "\n",
    "### 1. ¿Cuál es el problema del gradiente de fuga en las redes LSTM y cómo afecta la efectividad de LSTM para el pronóstico de series temporales? \n",
    "El problema del gradiente de fuga en las redes LSTM, es que aunque las LSTM están diseñadas para mitigarlo no son inmunes, ya que en LSTM el estado de la celda va de esta manera:\n",
    "\n",
    "$$\n",
    "c_t = f_t \\odot c_{t-1} + i_t \\odot g_t\n",
    "$$\n",
    "\n",
    "Y en la retropropagación a través del tiempo hace que la gradiente hacia:\n",
    "$$\n",
    "c_{t-1}\n",
    "$$\n",
    "\n",
    "se multiplique por el producto de las compuertas del olvido, entonces el resultado del producto tiende a 0 cuando la secuencia es larga o las compuertas se cierran más, entonces el gradiente se desvanece y si fuera mayor que 1 explotaría. Y eso pasa en la práctuca ya que se puede dar la saturación de sigmoides, sesgo del olvido mal iniciado, secuencias largas y normalización o escala pobre de entradas. Y esto afecta al pronóstico, porque no capta dependencias de largo plazo, tiene predicciones que sub-reaccionan a las señales antiguas, tiene una convergencia lenta y es inestable, ya que a varios pasos el error crece y el modelo olvida el contexto útil.\n",
    "\n",
    "\n",
    "### 2. ¿Cómo se aborda la estacionalidad en los datos de series temporales cuando se utilizan LSTM para realizar pronósticos y qué papel juega la diferenciación en el proceso? \n",
    "\n",
    "El manejo de estacionalidad en LSTM se puede modelar la estacionalidad como caracteristicas o al quitarla y recomponerla. Ya que, la diferenciación lo que hacec es estabilizar y facilitar el aprendizaje, pero requiere de reintegrar y puede sobreactuar si la estacionalidad no es rígida. En el caso que la estacionalidad sea fuerte o regular es mejor deseasonalizarla, quitarla al entrenar el LSTM sobre la serie limpua y reaplicar al estacionalidad al final. Mientras que si es informativa para el modelo, es mejor agregarlas como features exógenas.\n",
    "\n",
    "\n",
    "\n",
    "### 3. ¿Cuál es el concepto de \"tamaño de ventana\" en el pronóstico de series temporales con LSTM y cómo afecta la elección del tamaño de ventana a la capacidad del modelo para capturar patrones a corto y largo plazo? \n",
    "\n",
    "El concepto de tamaño de ventana o tambien llamado lookback o W, es cuantos pasos del pasado se le entrega al modelo para predecir el futuro. Y el W si es una ventana corta o pequeña, tiende a patrones de corto plazo, entonces este aprende rápidamente señales locales, pero no ve ciclos largos. Mientras que si es una ventana larga o grande, tiende a patrones de largo plazo, estos pueden capturar tendencias y estacionalidades largas si están presentes en la ventana, tiene parámetros más efectivos, mayor varianza/overfitting, y el entrenamiento es más lengo. Por el desvanecimiento de gradientes si la información útil está muy lejos el LSTM no puede aprovechar todo. Por lo tanto para evaluar el tamaño de la ventana y saber como ajustarla es imporante analizar la serie y su ciclo. Si la H es grande, los datos limitados para evitar W demasiado grandes y si tiene múltiples ciclos. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b528321c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
